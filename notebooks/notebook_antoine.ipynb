{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. reading .csv + preparing df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>subtopic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2 2 0 2  g u A 6 2  ] E H . h p - o r t s a [ ...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Draft version August 29, 2022 Typeset using LA...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Astronomy &amp; Astrophysics manuscript no. 41891c...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Astronomy &amp; Astrophysics manuscript no. aa Aug...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2 2 0 2  g u A 6 2  ]  R S . h p - o r t s a [...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0      subtopic\n",
       "0           0  2 2 0 2  g u A 6 2  ] E H . h p - o r t s a [ ...  Astrophysics\n",
       "1           1  Draft version August 29, 2022 Typeset using LA...  Astrophysics\n",
       "2           2  Astronomy & Astrophysics manuscript no. 41891c...  Astrophysics\n",
       "3           3  Astronomy & Astrophysics manuscript no. aa Aug...  Astrophysics\n",
       "4           4  2 2 0 2  g u A 6 2  ]  R S . h p - o r t s a [...  Astrophysics"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_path = \"../raw_data/\"\n",
    "path = \"small_dataset.csv\"\n",
    "## creating an absolute path to be able to run the code on every machine\n",
    "abs_path = os.path.abspath(pre_path + path)\n",
    "\n",
    "\n",
    "df = pd.read_csv(abs_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. preparing df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "    columns={\"Unnamed: 0\":\"Index\",\n",
    "        \"0\":\"paper_text\"}\n",
    "          ,inplace=True)\n",
    "df.set_index(\"Index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subtopic                                \n",
       "Mathematical Physics                        140\n",
       "High Energy Physics - Theory                100\n",
       "Astrophysics                                100\n",
       "Quantum Physics                             100\n",
       "Condensed Matter                            100\n",
       "High Energy Physics - Phenomenology          99\n",
       "General Relativity and Quantum Cosmology     95\n",
       "Combinatorics                                90\n",
       "Optimization and Control                     86\n",
       "Probability                                  85\n",
       "Analysis of PDEs                             84\n",
       "Nonlinear Sciences                           72\n",
       "Numerical Analysis                           67\n",
       "Algebraic Geometry                           59\n",
       "Dynamical Systems                            58\n",
       "Information Theory                           56\n",
       "High Energy Physics - Experiment             56\n",
       "Number Theory                                50\n",
       "Differential Geometry                        45\n",
       "Nuclear Theory                               42\n",
       "Functional Analysis                          42\n",
       "Statistics Theory                            40\n",
       "Representation Theory                        29\n",
       "Geometric Topology                           29\n",
       "Complex Variables                            28\n",
       "Rings and Algebras                           27\n",
       "Classical Analysis and ODEs                  27\n",
       "Algebraic Topology                           26\n",
       "Group Theory                                 25\n",
       "Commutative Algebra                          23\n",
       "Nuclear Experiment                           22\n",
       "Logic                                        15\n",
       "Operator Algebras                            15\n",
       "Quantum Algebra                              14\n",
       "General Mathematics                          13\n",
       "Metric Geometry                              13\n",
       "High Energy Physics - Lattice                13\n",
       "Category Theory                              11\n",
       "History and Overview                         11\n",
       "General Topology                              8\n",
       "Symplectic Geometry                           8\n",
       "K-Theory and Homology                         6\n",
       "Spectral Theory                               6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['subtopic']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Categories filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_lst_topics = [\"Algebraic Geometry\",\n",
    "\"Algebraic Topology\",\n",
    "\"Analysis of PDEs\", \n",
    "\"Category Theory\", \n",
    "\"Classical Analysis and ODEs\", \n",
    "\"Combinatorics\", \n",
    "\"Commutative Algebra\", \n",
    "\"Complex Variables\", \n",
    "\"Differential Geometry\", \n",
    "\"Dynamical Systems\", \n",
    "\"Functional Analysis\", \n",
    "\"General Mathematics\", \n",
    "\"General Topology\", \n",
    "\"Geometric Topology\", \n",
    "\"Group Theory\", \n",
    "\"History and Overview\", \n",
    "\"Information Theory\", \n",
    "\"K-Theory and Homology\", \n",
    "\"Logic; Mathematical Physics\", \n",
    "\"Metric Geometry\", \n",
    "\"Number Theory\", \n",
    "\"Numerical Analysis\", \n",
    "\"Operator Algebras\", \n",
    "\"Optimization and Control\",\n",
    "\"Probability; Quantum Algebra\", \n",
    "\"Representation Theory\", \n",
    "\"Rings and Algebras\", \n",
    "\"Spectral Theory\", \n",
    "\"Statistics Theory\", \n",
    "\"Symplectic Geometry\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_math_algebra = [\n",
    "    \"Algebraic Geometry\",\n",
    "    \"Algebraic Geometry\",\n",
    "    \"Algebraic Topology\",\n",
    "    \"Commutative Algebra\",\n",
    "    \"Differential Geometry\",\n",
    "    \"General Topology\",\n",
    "    \"Geometric Topology\",\n",
    "    \"Group Theory\",\n",
    "    \"Symplectic Geometry\",\n",
    "    \"Representation Theory\",\n",
    "    \"K-Theory and Homology\",\n",
    "    \"Category Theory\",\n",
    "    \"Quantum Algebra\",\n",
    "    \"Spectral Theory\",\n",
    "    \"Rings and Algebra\",\n",
    "    \"Operator Algebra\"\n",
    "]\n",
    "lst_math_num_analysis = [\n",
    "    \"Analysis of PDE\",\n",
    "    \"Classical Analysis and ODE\",\n",
    "    \"Functional Analysis\",\n",
    "    \"General Mathematics\",\n",
    "    \"Numerical Analysis\"\n",
    "]\n",
    "lst_math_opti = [\n",
    "    \"Dynamical Systems\",\n",
    "    \"Logic\",\n",
    "    \"Optimization and Control\"\n",
    "]\n",
    "lst_math_stat = [\n",
    "    \"Combinatorics\",\n",
    "    \"Probability\",\n",
    "    \"Statistics Theory\"\n",
    "]\n",
    "lst_math_rest = [\n",
    "    \"Mathematical Physic\",\n",
    "    \"Information Theory\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. add main topic column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df['subtopic'].apply(lambda x: 'mathematic' if x in math_lst_topics else 'physics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic     \n",
       "physics       1053\n",
       "mathematic     982\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['topic']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. test loading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['paper_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Cutting the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting_abs(text):\n",
    "    return text[text.find(\"ABSTRACT\")+8:]\n",
    "\n",
    "#df['paper_text'][0][df['paper_text'][0].find('ABSTRACT')+8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutting_abs(df['paper_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. lowercase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chdcdghhnjcndhdhebh'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase('chdcdGhHnjcndHDHEBH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Removing digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digit(text):\n",
    "    cleaned_text = ''.join(char for char in text if not char.isdigit())\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bhccfhdcbhdnjcdjncjdknkj'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_digit('73838bhccfhdcbhd3njcdj344ncjdknkj576')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Removing Punctuaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    cleaned_text = ''.join(char for char in text if char not in string.punctuation)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hd jcjd'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(':;:;:;))) hd jcjd!!(\"')\n",
    "#string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Removing special characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def try_with_regular_expression(text):\n",
    "    new_string = re.sub(r\"[^a-z]\",\" \",text)\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cndjncjd   e        '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_with_regular_expression('cndjncjd-)àe\"ç\"à\"à\"-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## must pip install cleantext\n",
    "#import cleantext\n",
    "#def normalize_space(text):\n",
    "#    normalized_string = cleantext.clean(string, normalize_whitespace=True)\n",
    "#    return normalized_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Normalize space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing it manually with split and strip\n",
    "def normalize_space_man(text):\n",
    "    lst_word = text.split()\n",
    "    return \" \".join(word for word in lst_word)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bonjour Je suis un adulte'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test  = 'Bonjour   Je suis un    adulte'\n",
    "normalize_space_man(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Removing single words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove single character word\n",
    "def remove_single(text):\n",
    "    lst_word = text.split()\n",
    "    return \" \".join(word for word in lst_word if len(word)>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'je suis un adulte'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_single('je suis e un z adulte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Global cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function all together\n",
    "def pre_clean_data(text):\n",
    "    cleaned_text = remove_single(normalize_space_man(try_with_regular_expression(remove_punctuation(remove_digit(lowercase(cutting_abs(text)))))))\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre_clean_data(df['paper_text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tokkenize, Lemmatize, remove stopsword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. tokkenizing lemm stopswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokkenize_words(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokkenize_words(df['paper_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(lst_word):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in lst_word if not word in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(lst_word):\n",
    "    # Lemmatizing the verbs\n",
    "    \n",
    "    verb_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"v\")  # v --> verbs\n",
    "                  for word in lst_word]\n",
    "\n",
    "    # 2 - Lemmatizing the nouns\n",
    "    noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\")  # n --> nouns\n",
    "                  for word in verb_lemmatized]\n",
    "    return noun_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_sw_lem(text):\n",
    "    return lemmatize(remove_stopwords(tokkenize_words(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put it back into a string for the deeplearning model\n",
    "def get_text_back(lst_word):\n",
    "    return \" \".join(word for word in lst_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_text_back(tok_sw_lem(pre_clean_data(df['paper_text'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pre_pro(text):\n",
    "    return get_text_back(tok_sw_lem(pre_clean_data(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating the list of pdf X and the target y For the main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['paper_text'][:3]\n",
    "X = df['paper_text'].apply(lambda x: final_pre_pro(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder()\n",
    "y = enc.fit_transform(df[['topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  144   318   328 ...     0     0     0]\n",
      " [ 6090  1977  4965 ...     0     0     0]\n",
      " [  820  8136 28213 ...     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2035, 45511)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "\n",
    "## Vectorizing data \n",
    "X_vect = pad_sequences(tokenizer.texts_to_sequences(X), padding=\"post\", value=0.)\n",
    "\n",
    "\n",
    "\n",
    "print(X_vect[:3])\n",
    "\n",
    "\n",
    "X_vect.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_test_vect, y_train, y_test = train_test_split(X_vect, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1363, 45511), (672, 45511), (1363, 1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape,X_test_vect.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185616"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Dense, Flatten\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 45511, 50)         9280850   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 45509, 20)         3020      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 910180)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 910181    \n",
      "=================================================================\n",
      "Total params: 10,194,051\n",
      "Trainable params: 10,194,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embed_len = 50\n",
    "\n",
    "# Conv1D\n",
    "cnn = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, input_length=X_train_vect.shape[1], output_dim=embed_len, mask_zero=True),\n",
    "    Conv1D(20, kernel_size=3),\n",
    "    Flatten(),\n",
    "    Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit(X_train_vect, y_train, epochs=5, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(X_test_vect,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('WorkingPaper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e586201604a5b35e9150247dec59911dfaaad6994608e828b5c764230b96f67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
