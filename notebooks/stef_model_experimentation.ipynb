{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:29:47.580766: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-08-30 17:29:47.629367: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-30 17:29:47.629399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, Sequential #, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Experimenting in order to get to a BaseModel\n",
    "#### with only minimal preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subtopic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 2 0 2  g u A 6 2  ] E H . h p - o r t s a [ ...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Draft version August 29, 2022 Typeset using LA...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astronomy &amp; Astrophysics manuscript no. 41891c...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Astronomy &amp; Astrophysics manuscript no. aa Aug...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 2 0 2  g u A 6 2  ]  R S . h p - o r t s a [...</td>\n",
       "      <td>Astrophysics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      subtopic\n",
       "0  2 2 0 2  g u A 6 2  ] E H . h p - o r t s a [ ...  Astrophysics\n",
       "1  Draft version August 29, 2022 Typeset using LA...  Astrophysics\n",
       "2  Astronomy & Astrophysics manuscript no. 41891c...  Astrophysics\n",
       "3  Astronomy & Astrophysics manuscript no. aa Aug...  Astrophysics\n",
       "4  2 2 0 2  g u A 6 2  ]  R S . h p - o r t s a [...  Astrophysics"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Data\n",
    "data = pd.read_csv('../raw_data/small_dataset.csv')\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "data = data.rename(columns={'0': 'text'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "data['modified text'] = data['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>subtopic</th>\n",
       "      <th>modified text</th>\n",
       "      <th>words per text</th>\n",
       "      <th>words per modified text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 2 0 2  g u A 6 2  ] E H . h p - o r t s a [ ...</td>\n",
       "      <td>Astrophysics</td>\n",
       "      <td>[2, 2, 0, 2, g, u, A, 6, 2, ], E, H, ., h, p, ...</td>\n",
       "      <td>58690</td>\n",
       "      <td>9146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Draft version August 29, 2022 Typeset using LA...</td>\n",
       "      <td>Astrophysics</td>\n",
       "      <td>[Draft, version, August, 29, ,, 2022, Typeset,...</td>\n",
       "      <td>55930</td>\n",
       "      <td>8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astronomy &amp; Astrophysics manuscript no. 41891c...</td>\n",
       "      <td>Astrophysics</td>\n",
       "      <td>[Astronomy, &amp;, Astrophysics, manuscript, ., 41...</td>\n",
       "      <td>46117</td>\n",
       "      <td>6262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Astronomy &amp; Astrophysics manuscript no. aa Aug...</td>\n",
       "      <td>Astrophysics</td>\n",
       "      <td>[Astronomy, &amp;, Astrophysics, manuscript, ., aa...</td>\n",
       "      <td>78395</td>\n",
       "      <td>12692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 2 0 2  g u A 6 2  ]  R S . h p - o r t s a [...</td>\n",
       "      <td>Astrophysics</td>\n",
       "      <td>[2, 2, 0, 2, g, u, A, 6, 2, ], R, S, ., h, p, ...</td>\n",
       "      <td>61921</td>\n",
       "      <td>9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>2 2 0 2  g u A 3 2  ]  A F . h t a m  [  1 v 5...</td>\n",
       "      <td>Symplectic Geometry</td>\n",
       "      <td>[2, 2, 0, 2, g, u, A, 3, 2, ], A, F, ., h, [, ...</td>\n",
       "      <td>70325</td>\n",
       "      <td>12866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>UNIVERSIDAD COMPLUTENSE DE MADRID  FACULTAD DE...</td>\n",
       "      <td>Symplectic Geometry</td>\n",
       "      <td>[UNIVERSIDAD, COMPLUTENSE, DE, MADRID, FACULTA...</td>\n",
       "      <td>79210</td>\n",
       "      <td>18640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>2 2 0 2  g u A 0 2  ]  G S . h t a m  [  1 v 4...</td>\n",
       "      <td>Symplectic Geometry</td>\n",
       "      <td>[2, 2, 0, 2, g, u, A, 0, 2, ], G, S, ., h, [, ...</td>\n",
       "      <td>46697</td>\n",
       "      <td>9457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>2 2 0 2  g u A 6 1  ]  G S . h t a m  [  1 v 4...</td>\n",
       "      <td>Symplectic Geometry</td>\n",
       "      <td>[2, 2, 0, 2, g, u, A, 6, 1, ], G, S, ., h, [, ...</td>\n",
       "      <td>26625</td>\n",
       "      <td>5040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>Free ﬁeld realisation and the chiral universal...</td>\n",
       "      <td>Symplectic Geometry</td>\n",
       "      <td>[Free, ﬁeld, realisation, chiral, universal, c...</td>\n",
       "      <td>144101</td>\n",
       "      <td>26877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2035 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text             subtopic  \\\n",
       "0     2 2 0 2  g u A 6 2  ] E H . h p - o r t s a [ ...         Astrophysics   \n",
       "1     Draft version August 29, 2022 Typeset using LA...         Astrophysics   \n",
       "2     Astronomy & Astrophysics manuscript no. 41891c...         Astrophysics   \n",
       "3     Astronomy & Astrophysics manuscript no. aa Aug...         Astrophysics   \n",
       "4     2 2 0 2  g u A 6 2  ]  R S . h p - o r t s a [...         Astrophysics   \n",
       "...                                                 ...                  ...   \n",
       "2030  2 2 0 2  g u A 3 2  ]  A F . h t a m  [  1 v 5...  Symplectic Geometry   \n",
       "2031  UNIVERSIDAD COMPLUTENSE DE MADRID  FACULTAD DE...  Symplectic Geometry   \n",
       "2032  2 2 0 2  g u A 0 2  ]  G S . h t a m  [  1 v 4...  Symplectic Geometry   \n",
       "2033  2 2 0 2  g u A 6 1  ]  G S . h t a m  [  1 v 4...  Symplectic Geometry   \n",
       "2034  Free ﬁeld realisation and the chiral universal...  Symplectic Geometry   \n",
       "\n",
       "                                          modified text  words per text  \\\n",
       "0     [2, 2, 0, 2, g, u, A, 6, 2, ], E, H, ., h, p, ...           58690   \n",
       "1     [Draft, version, August, 29, ,, 2022, Typeset,...           55930   \n",
       "2     [Astronomy, &, Astrophysics, manuscript, ., 41...           46117   \n",
       "3     [Astronomy, &, Astrophysics, manuscript, ., aa...           78395   \n",
       "4     [2, 2, 0, 2, g, u, A, 6, 2, ], R, S, ., h, p, ...           61921   \n",
       "...                                                 ...             ...   \n",
       "2030  [2, 2, 0, 2, g, u, A, 3, 2, ], A, F, ., h, [, ...           70325   \n",
       "2031  [UNIVERSIDAD, COMPLUTENSE, DE, MADRID, FACULTA...           79210   \n",
       "2032  [2, 2, 0, 2, g, u, A, 0, 2, ], G, S, ., h, [, ...           46697   \n",
       "2033  [2, 2, 0, 2, g, u, A, 6, 1, ], G, S, ., h, [, ...           26625   \n",
       "2034  [Free, ﬁeld, realisation, chiral, universal, c...          144101   \n",
       "\n",
       "      words per modified text  \n",
       "0                        9146  \n",
       "1                        8499  \n",
       "2                        6262  \n",
       "3                       12692  \n",
       "4                        9731  \n",
       "...                       ...  \n",
       "2030                    12866  \n",
       "2031                    18640  \n",
       "2032                     9457  \n",
       "2033                     5040  \n",
       "2034                    26877  \n",
       "\n",
       "[2035 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords Removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "data['modified text'] = data['modified text'].apply(lambda x: [word for word in x if not word in stop_words])\n",
    "data['words per text'] = data['text'].apply(lambda x : len(x)) \n",
    "data['words per modified text'] = data['modified text'].apply(lambda x : len(x)) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'subtopic', 'modified text', 'words per text',\n",
       "       'words per modified text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/stefanie/code/WorkingPaper/notebooks/stef_model_experimentation.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stefanie/code/WorkingPaper/notebooks/stef_model_experimentation.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Add Padding\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stefanie/code/WorkingPaper/notebooks/stef_model_experimentation.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mmodified text padded\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pad_sequences(data[\u001b[39m'\u001b[39;49m\u001b[39mmodified text\u001b[39;49m\u001b[39m'\u001b[39;49m], dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mfloat32\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m'\u001b[39;49m, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/WorkingPaper/lib/python3.8/site-packages/keras/utils/data_utils.py:1041\u001b[0m, in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m   1038\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTruncating type \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtruncating\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m not understood\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1040\u001b[0m \u001b[39m# check `trunc` has expected shape\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m trunc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(trunc, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m trunc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:] \u001b[39m!=\u001b[39m sample_shape:\n\u001b[1;32m   1043\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mShape of sample \u001b[39m\u001b[39m{\u001b[39;00mtrunc\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m of sequence at \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1044\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mposition \u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m is different from expected shape \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1045\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msample_shape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'g'"
     ]
    }
   ],
   "source": [
    "# Add Padding\n",
    "data['modified text padded'] = pad_sequences(data['modified text'], dtype='float32', padding='post', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Target Encoding, but turning subtopics into topics first\n",
    "def target_encoding():\n",
    "    \n",
    "\n",
    "data['subtopic'].map_apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['modified text'], data['subtopic'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading a pre-trained model, based on a 50 space vector representation from wikidata\n",
    "model_wiki = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wiki['saturn'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = datapath('~/gensim-data/glove-wiki-gigaword-50/glove-wiki-gigaword-50.gz')\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "#tmp_file = data['modified text']\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "glove_vectors = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wiki.most_similar(\"glass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network architechture with three components:\n",
    "\n",
    "    An embedding layer that generates word embedding, and the parameters are shared across words.\n",
    "    A hidden layer of one or more layers, which introduces non-linearity to the embeddings.\n",
    "    A softmax function that produces probability distribution over all the words in the vocabulary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50 # same as in the pretrained model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.LSTM(20))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "736150739e4fb3df6051488b43d6994f529cd492b8cd4a40882204b23398c180"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
